import asyncio
import logging
import time
import traceback
import argparse
from datetime import date
from pathlib import Path
from dataclasses import asdict

# --- Import c√°c th√†nh ph·∫ßn Core & Utils ---
from src.utils.logger import setup_logging
from src.utils.env_utils import get_config
from src.data_pipeline.loaders.gdrive_loader import GoogleDriveLoader
from src.data_pipeline.loaders.email_notifier import EmailNotifier

# --- Import "Nh·∫°c tr∆∞·ªüng" ---
from src.data_pipeline.orchestration.orchestrator import PipelineOrchestrator

# --- C·∫•u h√¨nh Logging ---
setup_logging('INFO')
logger = logging.getLogger(__name__)
# Gi·∫£m log nhi·ªÖu t·ª´ c√°c th∆∞ vi·ªán b√™n ngo√†i
logging.getLogger("googleapiclient").setLevel(logging.WARNING)
logging.getLogger("urllib3").setLevel(logging.WARNING)


async def main():
    """
    ƒêi·ªÉm kh·ªüi ƒë·∫ßu (Entry Point) c·ªßa to√†n b·ªô ·ª©ng d·ª•ng.
    Ch·ªãu tr√°ch nhi·ªám ph√¢n t√≠ch tham s·ªë, ƒëi·ªÅu ph·ªëi v√† b√°o c√°o.
    """
    parser = argparse.ArgumentParser(description="Ch·∫°y c√°c pipeline ETL cho Kin Hotel.")
    parser.add_argument(
        "pipeline", 
        choices=['booking', 'dimensions', 'room_lock', 'odoo', 'all'], 
        help="T√™n pipeline c·∫ßn ch·∫°y."
    )
    args = parser.parse_args()

    pipeline_start_time = time.time()
    EXECUTION_DATE = date.today()
    
    report = {
        "execution_date": EXECUTION_DATE.isoformat(), 
        "overall_status": "SUCCESS",
        "pipeline_name": f"'{args.pipeline.upper()}' Pipeline",
        "staging": {}, 
        "historical": {}, 
        "dwh": {}, 
        "gdrive": {}, 
        "error": None,
        "total_time_seconds": 0
    }

    orchestrator = None
    try:
        config = get_config()
        paths = config['paths']
        orchestrator = PipelineOrchestrator(config, report)
        
        # Giao to√†n b·ªô vi·ªác ch·∫°y pipeline cho "Nh·∫°c tr∆∞·ªüng"
        await orchestrator.run(args.pipeline)

        # === GIAI ƒêO·∫†N CU·ªêI 1: T·∫¢I D·ªÆ LI·ªÜU L√äN GDRIVE ===
        logger.info("\nPHASE FINAL 1: LOADING ALL DATA LAYERS TO GOOGLE DRIVE...")
        gdrive_loader = GoogleDriveLoader(
            sa_path=config['gdrive']['sa_path'], 
            root_folder_id=config['gdrive']['folder_id']
        )
        upload_date_str = EXECUTION_DATE.strftime('%Y-%m-%d')
        layers_to_upload = {
            "staging": paths['staging_dir'], 
            "historical": paths['historical_dir'], 
            "dwh": paths['datawarehouse_dir'],
            "quarantine": paths['quarantine_dir']
        }
        for layer_name, local_path in layers_to_upload.items():
            if Path(local_path).exists():
                gdrive_target_folder = f"data_lake/{layer_name}/{upload_date_str}"
                upload_result = gdrive_loader.load(
                    local_path=str(local_path), 
                    target_subfolder=gdrive_target_folder
                )
                report["gdrive"][layer_name] = asdict(upload_result)
    
    except Exception as e:
        logger.exception(f"üí• PIPELINE FAILED with critical error: {e}")
        report["overall_status"] = "FAILED"
        report["error"] = traceback.format_exc()
    
    finally:
        if orchestrator:
            await orchestrator.close_resources() # ƒê√≥ng t·∫•t c·∫£ k·∫øt n·ªëi (PMS client, etc.)
            
        pipeline_end_time = time.time()
        report["total_time_seconds"] = pipeline_end_time - pipeline_start_time
        
        # === GIAI ƒêO·∫†N CU·ªêI 2: G·ª¨I EMAIL B√ÅO C√ÅO ===
        logger.info("\n--- PHASE FINAL 2: SENDING FINAL REPORT ---")
        email_cfg = config['email']
        email_notifier = EmailNotifier(
            smtp_server="smtp.gmail.com", 
            port=587,
            sender=email_cfg['sender'], 
            password=email_cfg['password'], 
            recipient=email_cfg['recipient']
        )
        email_notifier.load(report_data=report)
        
        final_status_msg = f"üéâ PIPELINE '{args.pipeline.upper()}' FINISHED in {report['total_time_seconds']:.2f}s. Status: {report['overall_status']}"
        logger.info("=" * len(final_status_msg))
        logger.info(final_status_msg)
        logger.info("=" * len(final_status_msg))

if __name__ == "__main__":
    asyncio.run(main())