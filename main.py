# main.py
import asyncio
import logging
from datetime import datetime

# --- CHANGE: Thay ƒë·ªïi ƒë∆∞·ªùng d·∫´n n√†y cho ƒë√∫ng v·ªõi c·∫•u tr√∫c d·ª± √°n c·ªßa b·∫°n ---
from data_pipeline.extractors.pms.booking import BookingListExtractor

async def main():
    """
    H√†m ch√≠nh ƒë·ªÉ ch·∫°y pipeline ETL.
    """
    # 1. Thi·∫øt l·∫≠p Logging ƒë·ªÉ theo d√µi ti·∫øn tr√¨nh
    logging.basicConfig(
        level=logging.INFO,
        format='[%(asctime)s] [%(name)s] [%(levelname)s] %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    logger = logging.getLogger("MAIN_PIPELINE")

    extractor = None
    start_time = datetime.now()
    logger.info("üöÄ Starting the main ETL pipeline to extract bookings...")

    try:
        # 2. Kh·ªüi t·∫°o Extractor
        # L·ªõp n√†y gi·ªù ƒë√£ ch·ª©a t·∫•t c·∫£ logic c·∫ßn thi·∫øt.
        extractor = BookingListExtractor()

        # 3. Ch·∫°y qu√° tr√¨nh l·∫•y d·ªØ li·ªáu tƒÉng tr∆∞·ªüng (Incremental Extraction)
        # B·∫†N CH·ªà C·∫¶N G·ªåI M·ªòT H√ÄM DUY NH·∫§T N√ÄY.
        # N√≥ s·∫Ω t·ª± ƒë·ªông:
        #  - T·∫£i timestamp c·ªßa l·∫ßn ch·∫°y cu·ªëi.
        #  - T√≠nh to√°n kho·∫£ng th·ªùi gian c·∫ßn l·∫•y.
        #  - Chuy·ªÉn ƒë·ªïi m√∫i gi·ªù sang UTC+7 cho API.
        #  - L·∫•y h·∫øt t·∫•t c·∫£ c√°c trang d·ªØ li·ªáu (pagination).
        #  - L∆∞u l·∫°i timestamp m·ªõi sau khi th√†nh c√¥ng.
        results = await extractor.extract_bookings_incrementally(
            lookback_days=7,  # Ch·ªâ d√πng cho l·∫ßn ch·∫°y ƒë·∫ßu ti√™n c·ªßa m·ªói chi nh√°nh
            limit=100         # S·ªë l∆∞·ª£ng b·∫£n ghi m·ªói trang
        )

        # 4. X·ª≠ l√Ω v√† t√≥m t·∫Øt k·∫øt qu·∫£
        logger.info("--- PIPELINE RESULTS ---")
        total_records = 0
        success_branches = 0
        for branch_id, result in results.items():
            if result.is_success:
                logger.info(f"‚úÖ Branch '{result.branch_name}': SUCCESS - Fetched {result.record_count} records.")
                total_records += result.record_count
                success_branches += 1
                # T·∫°i ƒë√¢y, b·∫°n c√≥ th·ªÉ th√™m logic ƒë·ªÉ l∆∞u result.data v√†o database ho·∫∑c file.
                # V√≠ d·ª•: await save_to_database(result.data)
            else:
                logger.error(f"‚ùå Branch '{result.branch_name}': FAILED - Error: {result.error}")

        duration = (datetime.now() - start_time).total_seconds()
        logger.info("--- PIPELINE SUMMARY ---")
        logger.info(f"‚úÖ Successfully extracted from {success_branches}/{len(results)} branches.")
        logger.info(f"üìä Total new records fetched: {total_records}")
        logger.info(f"‚è±Ô∏è Total pipeline duration: {duration:.2f} seconds.")

    except Exception as e:
        logger.critical(f"üí• A critical error occurred in the pipeline: {e}", exc_info=True)
    finally:
        # 5. LU√îN LU√îN d·ªçn d·∫πp t√†i nguy√™n, d√π th√†nh c√¥ng hay th·∫•t b·∫°i
        if extractor:
            logger.info("üßπ Cleaning up extractor resources (closing network sessions)...")
            await extractor.close()
            logger.info("‚úÖ Cleanup complete.")

if __name__ == "__main__":
    asyncio.run(main())